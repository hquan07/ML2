{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "196e6c06",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753164ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb074a6",
   "metadata": {},
   "source": [
    "# 2. Generate synthetic HAR-like dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab777823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_synthetic_har_data():\n",
    "    n_samples, n_features = 1000, 50\n",
    "    X = np.random.randn(n_samples, n_features)\n",
    "    y = np.random.randint(1, 7, size=n_samples)\n",
    "    \n",
    "    feature_names = [f\"feature_{i+1}\" for i in range(n_features)]\n",
    "    activity_map = {\n",
    "        1: \"WALKING\", 2: \"WALKING_UPSTAIRS\", 3: \"WALKING_DOWNSTAIRS\",\n",
    "        4: \"SITTING\", 5: \"STANDING\", 6: \"LAYING\"\n",
    "    }\n",
    "    y_names = [activity_map[label] for label in y]\n",
    "    \n",
    "    return X, y, y_names, feature_names, activity_map\n",
    "\n",
    "X, true_labels, activity_names, feature_names, activity_map = load_synthetic_har_data()\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Activities: {list(activity_map.values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed4179a",
   "metadata": {},
   "source": [
    "# 3.  Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebf6ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X):\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(X)\n",
    "\n",
    "X_processed = preprocess_data(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2128102",
   "metadata": {},
   "source": [
    "# 4. Run K-Means experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea19710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kmeans_experiment(X, k_values, n_init=10, max_iter=300, random_state=42):\n",
    "    results = {}\n",
    "    for k in k_values:\n",
    "        print(f\"Running k-means with k={k}...\")\n",
    "        kmeans = KMeans(n_clusters=k, init='k-means++', n_init=n_init, max_iter=max_iter, random_state=random_state)\n",
    "        kmeans.fit(X)\n",
    "        results[k] = {'model': kmeans, 'labels': kmeans.labels_}\n",
    "    return results\n",
    "\n",
    "k_values = [2, 3, 4, 5, 6, 8, 10, 12]\n",
    "kmeans_results = run_kmeans_experiment(X_processed, k_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caff667",
   "metadata": {},
   "source": [
    "# 5. Evaluate clustering quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f523fd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_clustering_quality(X, kmeans_results):\n",
    "    metrics = {}\n",
    "    for k, result in kmeans_results.items():\n",
    "        labels = result['labels']\n",
    "        model = result['model']\n",
    "        metrics[k] = {\n",
    "            'inertia': model.inertia_,\n",
    "            'silhouette': silhouette_score(X, labels) if k > 1 else 0,\n",
    "            'calinski_harabasz': calinski_harabasz_score(X, labels) if k > 1 else 0,\n",
    "            'davies_bouldin': davies_bouldin_score(X, labels) if k > 1 else float('inf')\n",
    "        }\n",
    "    return metrics\n",
    "\n",
    "quality_metrics = calculate_clustering_quality(X_processed, kmeans_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434aa8ad",
   "metadata": {},
   "source": [
    "# 6. Save metrics to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bd51f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics_to_csv(metrics):\n",
    "    df = pd.DataFrame([{'k': k, **m} for k, m in metrics.items()]).sort_values('k')\n",
    "    df.to_csv('C:/ML/Labwork2/dataset/kmeans_quality_metrics.csv', index=False)\n",
    "\n",
    "save_metrics_to_csv(quality_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5694aa4",
   "metadata": {},
   "source": [
    "# 7. Evaluate clustering vs true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fcb16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clustering(true_labels, kmeans_results, activity_map):\n",
    "    evaluation = {}\n",
    "    for k, result in kmeans_results.items():\n",
    "        cluster_labels = result['labels']\n",
    "        contingency = pd.crosstab(pd.Series(cluster_labels, name='Cluster'),\n",
    "                                  pd.Series([activity_map[l] for l in true_labels], name='Activity'))\n",
    "        cluster_homogeneity = {\n",
    "            cluster_id: {\n",
    "                'dominant_activity': cluster_counts.idxmax(),\n",
    "                'homogeneity': cluster_counts.max() / cluster_counts.sum()\n",
    "            }\n",
    "            for cluster_id, cluster_counts in contingency.iterrows()\n",
    "        }\n",
    "        evaluation[k] = {'contingency': contingency, 'cluster_homogeneity': cluster_homogeneity}\n",
    "    return evaluation\n",
    "\n",
    "evaluation = evaluate_clustering(true_labels, kmeans_results, activity_map)\n",
    "\n",
    "# Show contingency for k=6\n",
    "evaluation[6]['contingency']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eb2d63",
   "metadata": {},
   "source": [
    "# 8. Visualize clusters in 2D (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd520b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_processed)\n",
    "\n",
    "# Convert true labels to numeric values\n",
    "true_numeric = [list(activity_map.keys())[list(activity_map.values()).index(name)] \n",
    "                for name in [activity_map[l] for l in true_labels]]\n",
    "\n",
    "save_dir = \"C:/ML/Labwork2\"\n",
    "\n",
    "for k, result in kmeans_results.items():\n",
    "    if k > 10:\n",
    "        continue\n",
    "    cluster_labels = result['labels']\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    # Left: K-means Clusters\n",
    "    ax1.scatter(X_pca[:, 0], X_pca[:, 1], c=cluster_labels, cmap='viridis', alpha=0.6)\n",
    "    ax1.set_title(f'K-means Clusters (k={k})')\n",
    "\n",
    "    # Right: True Activities\n",
    "    ax2.scatter(X_pca[:, 0], X_pca[:, 1], c=true_numeric, cmap='tab10', alpha=0.6)\n",
    "    ax2.set_title('True Activities')\n",
    "\n",
    "    plt.savefig(f\"{save_dir}clusters_vs_true_k{k}.png\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d843a7",
   "metadata": {},
   "source": [
    "# 9. Visualize metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f8470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_metrics(metrics):\n",
    "    k_vals = sorted(metrics.keys())\n",
    "    inertia = [metrics[k]['inertia'] for k in k_vals]\n",
    "    silhouette = [metrics[k]['silhouette'] for k in k_vals]\n",
    "    ch_index = [metrics[k]['calinski_harabasz'] for k in k_vals]\n",
    "    db_index = [metrics[k]['davies_bouldin'] for k in k_vals]\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    axs[0, 0].plot(k_vals, inertia, 'bo-'); axs[0, 0].set_title(\"Elbow (Inertia)\")\n",
    "    axs[0, 1].plot(k_vals, silhouette, 'go-'); axs[0, 1].set_title(\"Silhouette Score\")\n",
    "    axs[1, 0].plot(k_vals, ch_index, 'ro-'); axs[1, 0].set_title(\"Calinski-Harabasz Index\")\n",
    "    axs[1, 1].plot(k_vals, db_index, 'mo-'); axs[1, 1].set_title(\"Davies-Bouldin Index\")\n",
    "    for ax in axs.flat: ax.set_xlabel(\"Number of Clusters (k)\"); ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"C:/ML/Labwork2/visualizations/HAR_metrics.png\")\n",
    "    plt.show()\n",
    "\n",
    "visualize_metrics(quality_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79c76d0",
   "metadata": {},
   "source": [
    "# 10. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb09112",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k_silhouette = max(quality_metrics, key=lambda k: quality_metrics[k]['silhouette'])\n",
    "best_k_calinski = max(quality_metrics, key=lambda k: quality_metrics[k]['calinski_harabasz'])\n",
    "best_k_davies = min(quality_metrics, key=lambda k: quality_metrics[k]['davies_bouldin'])\n",
    "\n",
    "print(f\"Best k (Silhouette): {best_k_silhouette}\")\n",
    "print(f\"Best k (Calinski-Harabasz): {best_k_calinski}\")\n",
    "print(f\"Best k (Davies-Bouldin): {best_k_davies}\")\n",
    "print(\"Ground truth: 6 activities\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
